{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การควบคุมเหมาะที่สุดและการเรียนรูู้เสริมกำลัง -- ดร.วโรดม ตู้จินดา"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 การควบคุมเหมาะที่สุดแบบสโทแคสติก\n",
    "\n",
    "จากการศึกษาในบทที่ผ่านมา เราตั้งสมมุติฐานว่าทุกสิ่งทุกอย่างบนโลกนี้เป็นแบบเชิงกำหนด ทำให้สามารถพยากรณ์ค่าในอนาคตได้อย่างแม่นยำ\n",
    "ซึ่งในความเป็นจริงไม่เป็นเช่นนั้น ค่าที่วัดได้จากเซนเซอร์มีการรบกวนจากภายนอก รวมถึงความไม่แม่นยำของตัวเซนเซอร์เอง \n",
    "เราสามารถโมเดลการรบกวนเหล่านี้เป็นค่าสุ่ม ทำให้กลายเป็นปัญหา \n",
    "*การควบคุมเหมาะที่สุดแบบสโทแคสติก (stochastic optimal control)* ที่เป็นเนื้อหาหลักของบทนี้ \n",
    "ในการศึกษาจะเริ่มจากภาพรวมของปัญหาสโทแคสติก \n",
    "ลงสู่กรณีพิเศษเมื่อประมาณค่าพลวัตเป็นเชิงเส้นและใช้ตัวควบคุมที่เสมือนเป็นการขยายจากวิธีการที่ใช้ในระบบเชิงกำหนด \n",
    "\n",
    "ปัญหาสโทแคสติกโดยรวมครอบคลุมเนื้อหาที่กว้างมากและเป็นพื้นฐานของการเรียนรู้เสริมกำลัง \n",
    "ความรู้ในบทนี้เป็นเพียงฐานเพื่อต่อยอดไปยังแนวทางตามที่ต้องการ\n",
    "\n",
    "## 8.1 ปัญหาการควบคุมแบบสโทแคสติก\n",
    "\n",
    "ในการควบคุมก่อนหน้านี้เราสมมุติว่าทราบสถานะของระบบโดยสมบูรณ์ (ค่าผิดพลาดจากการโมเดลเป็นแบบเชิงกำหนด) คำถามที่สอดคล้องกับความจริงในทางปฎิบัติคือ จะเกิดอะไรขึ้นหากค่าที่วัดได้มีการรบกวนแบบสุ่ม (random noise)?  โดยทั่วไปแล้วเราอาจไม่สามารถวัดค่าสถานะทั้งหมดได้ ดังนั้นนิยามค่าจากการวัด $y$ เป็นฟังก์ชันของสถานะ $x$ และการรบกวน $v$\n",
    "$$\n",
    "y = g(x,v) \\tag{8.1}\n",
    "$$\n",
    "กล่าวคือในระบบเชิงกำหนดเราทราบสถานะ $x$ อย่างถูกต้องสมบูรณ์และใช้ในตัวควบคุมป้อนกลับ แต่สำหรับระบบสโทแคสติก เราทราบเพียงค่าจากการวัด $y$ ดังนั้นต้องใช้ฟังก์ชันความหนาแน่น (density function) $p(x|y)$ คือความน่าจะเป็นในการประมาณค่า $x$ เมื่อกำหนดค่า $y$ \n",
    "\n",
    "**หมายเหตุ :** ศัพท์ที่ใช้เรียก $y$ คือ POMDP ย่อมาจากกระบวนการตัดสินใจมาร์คอฟที่สังเกตได้บางส่วน (Partially-Observed Markov Decision Process) \n",
    "\n",
    "นิยามปัญหาการควบคุมเหมาะที่สุดแบบสโทแคสติกได้ดังนี้\n",
    "$$\n",
    "\\underset{u}{min} \\; E[J(x,u)] \\tag{8.2}\n",
    "$$\n",
    "โดย $E[.]$ แทนค่าคาดหมาย (expected value) แม้ว่าโดยหลักการแล้วเราสามารถแก้ปัญหาสโทแคสติกได้โดยใช้เครื่องมือเช่น \n",
    "DP หลังจากที่ครอบโดย $E[.]$ แล้วก็ตาม แต่ในกรณีทั่วไปปัญหาจะยากขึ้นมากจากฟังก์ชันความหนาแน่น \n",
    "ยกเว้นในกรณีที่เป็นแบบเกาส์เซียน \n",
    "เพราะสามารถแยกพารามิเตอร์เป็นเวกเตอร์ของค่าเฉลี่ยและเมทริกซ์ความแปรปรวนร่วมเกี่ยว (covariance)\n",
    "\n",
    "### 8.1.1 ตัวควบคุมกำลังสองเชิงเส้นแบบเกาส์เซียน\n",
    "\n",
    "กรณีพิเศษของการควบคุมแบบสโทแคสติกที่สามารถหาคำตอบในรูปปิดได้มีชื่อเรียกว่า *ตัวควบคุมกำลังสองเชิงเส้นแบบเกาส์เซียน (Linear Quadratic Gaussian)* ต่อไปจะเรียกโดยย่อว่า LQG \n",
    "พิจารณาได้เป็นการขยายจากตัวควบคุม LQR ที่ใช้มาโดยตลอดในระบบเชิงกำหนด \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## บรรณานุกรม\n",
    "\n",
    "1. Z. Manchester et.al. [16-745 Optimal Control & Reinforcement Learning, \n",
    "Course materials](https://optimalcontrol.ri.cmu.edu/#learning-resources), Carnegie Mellon University. 2025.\n",
    "\n",
    "2. R. Tedrake. [Underactuated Robotics: Algorithms for Walking, Running, Swimming, Flying, and Manipulation (Course Notes for MIT 6.832)](https://underactuated.csail.mit.edu). 2023. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## โจทย์ปัญหา"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://raw.githubusercontent.com/dewdotninja/sharing-github/refs/heads/master/dewninja_logo50.jpg\" alt=\"dewninja\"/>\n",
    "</div>\n",
    "<div align=\"center\">dew.ninja 2025</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (controlenv)",
   "language": "python",
   "name": "controlennv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
