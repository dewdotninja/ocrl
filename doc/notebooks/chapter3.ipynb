{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การควบคุมเหมาะที่สุดและการเรียนรูู้เสริมกำลัง -- ดร.วโรดม ตู้จินดา"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 การควบคุมเหมาะที่สุด\n",
    "\n",
    "หลังจากที่ได้ศึกษาเกี่ยวกับพื้นฐานการหาค่าเหมาะที่สุดในบทที่ 2 แล้ว ในบทนี้จะเริ่มต้นเข้าสู่การประุยุกต์ใช้งานในสาขาระบบควบคุม \n",
    "ซึ่งเป็นสาระสำคัญของหนังสือนี้ ดังที่ได้กล่าวแนะนำในบทแรกแล้วว่า \n",
    "แนวทางในการออกแบบและสร้างตัวควบคุมสมัยใหม่แตกต่างจากเดิมที่ใช้ตัวควบคุมที่มีโครงสร้างแน่นอน \n",
    "เช่นอยู่ในรูปของการป้อนกลับสถานะหรือเอาต์พุตผ่านอัตราขยายหรือสัมประสิทธิ์ฟังก์ชันถ่ายโอนที่เป็นค่าคงที่ \n",
    "โดยตัวควบคุมผ่านการออกแบบโดยวิธีการต่างๆ หรือหากเป็นตัวควบคุม PID \n",
    "จะอาศัยการปรับแต่งค่าพารามิเตอร์แบบออฟไลน์โดยผู้ใช้งานเพื่อได้ผลตอบสนองตามต้องการ \n",
    "การควบคุมปรับตัว (adaptive control) จะมีความยืดหยุ่นเพิ่มขึ้นโดยสามารถปรับค่าพารามิเตอร์อัตโนมัติในขณะทำงาน \n",
    "กล่าวได้ว่าเป็นการเรียนรู้ในรูปแบบหนึ่ง \n",
    "โดยบางวิธีการอาจมีความใกล้เคียงกับแนวทางที่นำเสนอในหนังสือนี้แต่อาจไม่ได้ถูกจัดรูปให้มองเห็นความสัมพันธ์อย่างชัดจน \n",
    "\n",
    "แท้จริงแล้วแนวทางการควบคุมเหมาะที่สุดมิได้เกิดขึ้นในยุคปัจจุบัน แต่เริ่มต้นตั้งแต่ในสมัยทศวรรษที่ 60 \n",
    "ของคริสต์ศักราช  เมื่อเริ่มมีการใช้คอมพิวเตอร์ช่วยในการวิเคราะห์และออกแบบระบบควบคุมในรูปปริภูมิสถานะ \n",
    "โดยการควบคุมป้อนกลับสถานะที่เรียกว่า ตัวควบคุมกำลังสองเชิงเส้น (linear quadratic regulator) \n",
    "ซึ่งต่อไปจะเรียกชื่อย่อว่า LQR ตัวกรองคาลมาน (Kalman filter หรือ KF) หรือรวมกันเรียกว่า \n",
    "ตัวควบคุมกำลังสองแบบเกาส์เซียน (linear quadratic gaussian หรือ LQG) ล้วนมีพื้นฐานบนวิธีการหาค่าเหมาะที่สุด \n",
    "เพียงแต่สมรรถนะของคอมพิวเตอร์ในสมัยนั้นไม่เพียงพอที่จะแก้ปัญหาเหมาะที่สุดแบบเรียลไทม์ ดังนั้น LQR, KF, LQG \n",
    "จะถูกสังเคราะห์แบบออฟไลน์เป็นอัตราขยายหรือฟังก์ชันถ่ายโอนคงที่ และอิมพลิเมนต์เป็นตัวควบคุมป้อนกลับที่ไม่มีการปรับแต่ง \n",
    "ในขณะใช้งาน ในขณะที่การแก้ปัญหาเหมาะที่สุดแบบออนไลน์ในการควบคุมแบบทำนายโมเดล (model predictive control หรือ MPC) \n",
    "มีการใช้งานจำกัดเฉพาะในระบบที่ตอบสนองช้าเช่นกระบวนการทางเคมี เนื่องจากการหาคำตอบแบบออนไลน์ต้องใช้เวลานาน \n",
    "\n",
    "เนื้อหาหลักในบทนี้ยังคงตามรอย [1] เสริมด้วยรายละเอียดจาก [2],[3]\n",
    "\n",
    "## 3.1 การควบคุมเหมาะที่สุดแบบเชิงกำหนด\n",
    "\n",
    "ประเด็นสำคัญที่แตกต่างระหว่างตัวควบคุมเหมาะที่สุดกับตัวควบคุมที่อาศัยการปรับแต่งพารามิเตอร์เช่น PID คือ \n",
    "ในการควบคุมเหมาะที่สุดเราจะกำหนดดรรชนีที่เป็นตัวชี้วัดว่าตัวควบคุมทำงานได้ดีมากน้อยเพียงใด เช่น \n",
    "ความแตกต่างในการตามรอยแนววิถีที่กำหนด ความเร็วในการทำงาน หรือดรรชนีอื่นตามต้องการ \n",
    "\n",
    "เริ่มต้นจากปัญหาการควบคุมเหมาะที่สุดแบบเชิงกำหนด (deterministic) \n",
    "ที่การหาคำตอบจะคงเดิมโดยไม่คำนึงถึงความไม่แน่นอนในตัวแปรเช่นสัญญาณรบกวน \n",
    "การควบคุมแบบเชิงกำหนดยังใช้ประโยชน์ได้มากสำหรับโจทย์ทั่วไปในสาขาระบบควบคุม \n",
    "เนื่องจากการรบกวนประเภทต่างๆ มีขนาดเล็กเมื่อเทียบกับสัญญาณคำสั่งอ้างอิง \n",
    "ส่วนความไม่แน่นอนในการโมเดลก็มิได้เป็นแบบสโทแคสติก (stochastic)\n",
    "เพราะค่าผิดพลาดระหว่างพลวัตจริงกับโมเดลไม่ใช่ค่าสุ่ม \n",
    "\n",
    "### 3.1.1 รูปแบบปัญหาในโดเมนเวลาต่อเนื่อง\n",
    "\n",
    "ตัวอย่างของโจทย์ปัญหาการควบคุมเหมาะที่สุดแบบเชิงกำหนดเป็นดังนี้ \n",
    "$$\n",
    "\\underset{x(t),u(t)}{min} \\; J(x(t),u(t)) = \\int_{t_0}^{t_f} l(x(t),u(t))\\,dt + l_F(x(t_f))  \n",
    "$$\n",
    "$$\n",
    "s.t. \\;\\; \\dot{x}(t) = f(x(t),u(t)),\n",
    "$$\n",
    "$$\n",
    "\\;\\; U_{min} \\le u(t) \\le U_{max} \\;\\; หรือ \\;\\; u(t) \\in \\mathscr{U}, \n",
    "$$\n",
    "$$\n",
    "\\;\\; c(x(t)) \\ge 0 \\tag{3.1}\n",
    "$$\n",
    "\n",
    "บรรทัดแรกคือฟังก์ชันมูลค่าซึ่งเป็นตัวชี้วัดสมรรถนะ ประกอบด้วยพจน์แรกที่อยู่ในปริพันธ์เรียกว่า มูลค่าขั้น (stage cost) และพจน์สุดท้ายคือ มูลค่าปลาย (terminal cost)\n",
    "\n",
    "การหาคำตอบคือคำนวณหาเอาต์พุตตัวควบคุมที่ทำให้ฟังก์ชันมูลค่านั้นน้อยที่สุด ใช้เอาต์พุตนั้นเป็นตัวขับเคลื่อนพลานต์ \n",
    "คือระบบที่ต้องการควบคุม \n",
    "\n",
    "ดังนั้นพลวัตของพลานต์เป็นเงื่อนไขบังคับสำคัญสำหรับปัญหาการควบคุมเหมาะที่สุด \n",
    "ซึ่งจะอยู่ในรูปเงื่อนไขบังคับสมการ นอกจากนั้นอาจมีเงื่อนไขบังคับอสมการเพิ่มเติม เช่นการจำกัดค่าของเอาต์พุตควบคุม เขียนได้ในรูปแบบขอบเขตล่างและบน $U_{min} \\le u(t) \\le U_{max}$หรือในกรณีทั่วไปคืออยู่ในเซตที่เป็นไปได้ $u(t) \\in \\mathscr{U}$\n",
    "ส่วนเงื่อนไขอื่นเช่นการจำกัดค่าสถานะหรือเอาต์พุตเพิ่อมิให้ชนกับสิ่งกีดขวาง เขียนในรูปทั่วไปคือ $c(x(t)) \\ge 0$  เพื่อสอดคล้องกับสัญนิยมที่ใช้ในบทที่ 2 โดยหากการจำกัดค่าอยู่ในรูป $\\tilde{c}(x(t)) \\le 0$ \n",
    "เพียงแต่กลับเครื่องหมาย $\\tilde{c}(x(t)) = -c(x(t))$ เท่านั้น\n",
    "\n",
    "**หมายเหตุ :** สำหรับผู้อ่านที่คุ้นเคยกับปัญหาการเรียนรู้เสริมกำลัง (ต่อไปจะเรียกย่อว่า RL)  ประเด็นสำคัญและคำศัพท์ที่แตกต่างพอสรุปได้คือ\n",
    "\n",
    "* ฟังก์ชันวัตถุประสงค์ในปัญหา RL อยู่ในรูปของรางวัล โดยต้องการหาค่าสูงสุดของรางวัลที่ได้รับ\n",
    "* เอาต์พุตของตัวควบคุมถูกเรียกว่าการกระทำ (action) หรือนโยบาย (policy)\n",
    "* พลานต์หรือพลวัตที่ต้องการควบคุมถูกเรียกว่าสภาพแวดล้อม (environment)\n",
    "* ใช้คำว่า ตัวกระทำ (agent) แทนตัวควบคุม\n",
    "* การเรียนรู้ในปัญหา RL ส่วนใหญ๋เป็นแบบออฟไลน์ ไม่มีเงื่อนไขเคร่งครัดด้านเวลาในการหาคำตอบ โดยฟังก์ชันวัตถุประสงค์เป็นแบบไม่เป็นเชิงเส้นและมักไม่เป็นแบบคอนเวกซ์ อาจมีตัวแปรตัดสินใจจำนวนมาก \n",
    "* ปัญหา RL โดยทั่วไปไม่จำเป็นต้องทำงานบนระบบที่ทรัพยากรจำกัด เช่นระบบฝังตัว   \n",
    "\n",
    "ข้อสังเกตสำหรับโจทย์ปัญหา (3.1)\n",
    "\n",
    "* ปัญหาการควบคุมเหมาะที่สุดในโดเมนเวลาต่อเนื่องมักถูกเรียกว่า มิติอนันต์ (infinite dimensional) มีที่มาจากกรณีของระบบดีสครึต (ที่เราจะให้ความสำคัญมากกว่า) จะเรียกแต่ละค่าของตัวแปร $x, u$ ว่า จุดเงื่อน (knot points) เหมือนที่ใช้ในฟังก์ชันเสมือนพหุนาม (spline functions) ในระบบเวลาต่อเนื่องเปรียบได้กับการเพิ่มจุดเงื่อนมากขึ้นจนเข้าสู่อนันต์\n",
    "* คำตอบจะอยู่ในรูปแนววิถีวงเปิด (open-loop trajectories) โดยไม่มีการควบคุมป้อนกลับ ซึ่งจะแตกต่างจากกรณีสโทแคสติก\n",
    "* ในบางปัญหาจะได้คำตอบเชิงวิเคราะห์ (analytic solutions) แต่มีไม่มากนัก\n",
    "\n",
    "### 3.1.2 รูปแบบปัญหาในโดเมนเวลาดีสครีต\n",
    "\n",
    "ตัวอย่างของปัญหาการควบคุมเหมาะที่สุดในโดเมนเวลาดีสครีตเขียนได้ดังนี้\n",
    "\n",
    "$$\n",
    "\\underset{x_{1:N},u_{1:N-1}}{min} \\; J(x_{1:N},u_{1:N-1}) =  \\sum_{k=1}^{N-1}l(x_k,u_k) + l_F(x_N)\n",
    "$$\n",
    "$$\n",
    "s.t. \\;\\; x_{k+1} = f(x_k,u_k),\n",
    "$$\n",
    "$$\n",
    "\\;\\; U_{min} \\le u_k \\le U_{max} \\;\\; หรือ \\;\\; u_k \\in \\mathscr{U} \\;\\; \\forall k, \n",
    "$$\n",
    "$$\n",
    "\\;\\; c(x_k) \\ge 0 \\;\\; \\forall k \\tag{3.2}\n",
    "$$\n",
    "\n",
    "โดยคำอธิบายสำหรับพจน์ทั้งหมดสอดคล้องกับกรณีเวลาต่อเนื่อง (3.1) เพียงแต่ค่าตัวแปรอยู่ในรูปของตัวอย่าง (samples) จำนวน $N$ ค่าสำหรับ $x_k$ และ $N-1$ ค่าสำหรับ $u_k$ พลวัตที่เป็นเงื่อนไขสมการและการจำกัดค่าในเงื่อนไขอสมการอยู่ในรูปดีสครีตทั้งหมด \n",
    "\n",
    "ข้อสังเกตสำหรับ (3.2)\n",
    "\n",
    "* ปัญหานี้เรียกว่ามิติจำกัด (finite dimensional)\n",
    "* ค่าตัวอย่าง $x_k, u_k$ มักถูกเรียกว่าจุดเงื่อน\n",
    "* การแปลงปัญหาจากเวลาต่อเนื่องเป็นดีสครีตทำได้โดยการประมาณค่าปริพันธ์วิธีต่างๆ เช่น ผลต่างข้างหน้า/ย้อนหลัง การแปลงเชิงเส้นคู่ หรือวิธีรุงเงคุตตา (Runge-Kutta)  \n",
    "* การแปลงปัญหาจากเวลาดีสครีตเป็นต่อเนื่องทำได้โดยการประมาณค่าในช่วง (interpolation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 หลักการค่าต่ำสุดของพอนเทรียกิน\n",
    "\n",
    "วิธีการแรกในการหาคำตอบเหมาะที่สุดอาศัยหลักการหาค่าต่ำสุดของพอนเทรียกิน (Pontryagin's minimum principle) \n",
    "ซึ่งมีต้นกำเนิดจากนักคณิตศาสตร์ชาวรัสเซีย Lev Semyonovich Pontryagin ในปี ค.ศ. 1956 \n",
    "(ชื่อเรียกในช่วงต้นกำเนิดคือการหาค่าสูงสุดของพอนเทรียกิน) โดยกล่าวถึงการแก้ปัญหาที่เรียกว่าระบบฮามิลโทเนียน (Hamiltonian) \n",
    "ซึ่งเป็นปัญหาค่าขอบ 2 จุด (two-point boundary value problem) \n",
    "และเป็นเงื่อนไขจำเป็นอันดับหนึ่งสำหรับระบบควบคุมเหมาะที่สุดแบบเชิงกำหนด ในระบบดีสครีตเป็นกรณีพิเศษของเงื่อนไข KKT\n",
    "\n",
    "**หมายเหตุ :** การอนุพัทธ์ดั้งเดิมกระทำในโดเมนเวลาต่อเนื่องโดยอาศัยแคลคูลัสการแปรผัน (calculus of variation) \n",
    "ซึ่งมีความเป็นคณิตศาสตร์ค่อนข้างมาก ดังนั้นแนวทางใน [1] จะอนุพัทธ์ในโดเมนดีสครีต  \n",
    "และหากต้องการแปลงเป็นผลในเวลาต่อเนื่องทำได้โดยลิมิตขั้นเวลาสู่ศูนย์ วิธีการนี้อาจไม่ถูกใจผู้ที่เคร่งทางคณิตศาสตร์เพราะจะมีปัญหาทางเทคนิคเล็กน้อยเช่นจุดไม่ต่อเนื่องของฟังก์ชัน แต่ไม่ใช่ปัญหาหลักด้านการประยุกตฺ์ใช้งาน \n",
    "\n",
    "จาก (3.2) เพื่อความง่ายในการอธิบายจะละทิ้งเงื่อนไขอสมการสำหรับ $x_k$ สร้างลากรานเจียนดังนี้\n",
    "$$\n",
    "L = \\sum_{k=1}^{N-1}l(x_k,u_k) + \\lambda_{k+1}^T(f(x_k,u_k)-x_{k+11})+l_F(x_k) \\tag{3.3}\n",
    "$$\n",
    "\n",
    "ในการอนุพัทธ์มักจะสร้างพจน์ที่เรียกว่าฮามิลโทเนียน\n",
    "$$\n",
    "H(x,u,\\lambda) = l(x,u) + \\lambda^T f(x,u) \\tag{3.4}\n",
    "$$\n",
    "\n",
    "เมื่อใช้ค่า $H$ ใน $L$ และใช้กลเม็ดในการดึงพจน์ออกจากผลรวมและเปลี่ยนค่าตัวชี้ จะได้ผลดังนี้ \n",
    "$$\n",
    "L = H(x_1,u_1,\\lambda_2) + \\left[\\sum_{k=2}^{N-1}H(x_k,u_k,\\lambda_{k+1})\n",
    "-\\lambda_k^Tx_k\\right] + l_F(x_N) - \\lambda_N^Tx_N \\tag{3.5}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## บรรณานุกรม\n",
    "\n",
    "1. Z. Manchester et.al. [16-745 Optimal Control & Reinforcement Learning, \n",
    "Course materials](https://optimalcontrol.ri.cmu.edu/#learning-resources), Carnegie Mellon University. 2024,2025.\n",
    "\n",
    "2. R. Tedrake. [Underactuated Robotics: Algorithms for Walking, Running, Swimming, Flying, and Manipulation (Course Notes for MIT 6.832)](https://underactuated.csail.mit.edu). 2023. \n",
    "\n",
    "3. D.P. Bertsekas. Reinforcement Learning and Optimal Control. MIT Press. 2019.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://raw.githubusercontent.com/dewdotninja/sharing-github/refs/heads/master/dewninja_logo50.jpg\" alt=\"dewninja\"/>\n",
    "</div>\n",
    "<div align=\"center\">dew.ninja 2025</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (controlenv)",
   "language": "python",
   "name": "controlennv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
