# ocrl
## หนังสือ "การควบคุมเหมาะที่สุดและการเรียนรู้เสริมกำลัง"
## Optimal Control and Reinforcement Learning

### ดร.วโรดม ตู้จินดา

repo นี้สำหรับหนังสือตามชื่อด้านบน เขียนไปเรื่อยตามโอกาสอำนวย เนื่องจากเนื้อหาส่วนใหญ๋เปลี่ยนแปลงตลอดเวลา จึงไม่มีหมายกำหนดการแล้วเสร็จ 
<hr>
<img src="https://raw.githubusercontent.com/dewdotninja/ocrl/refs/heads/main/doc/figs/ch2_eq_constraints.png" width=600 />
<hr>
 
### คำนำ

ในปัจจุบันที่คอมพิวเตอร์สมรรถนะสูงได้เข้ามามีส่วนในชีวิตของมนุษย์ในหลากหลายรูปแบบ ตั้งแต่อุปกรณ์เครื่องใช้ไฟฟ้า โทรศัพท์ รถยนต์ อุปกรณ์อำนวยความสะดวกต่างๆ จนถึงหุ่นยนต์ที่มีการพัฒนาอย่างต่อเนื่องเพื่อให้มีความฉลาด ตอบสนองความต้องการผู้ใช้งาน และปลอดภัยเมื่อทำงานอยู่ใกล้เรา (ผู้สอนวิชาหุ่นยนต์รายหนึ่งใช้คำว่า “huggable” ใช้การควบคุมแรงเพื่อทำให้เครื่องจักรกลโอนอ่อนตามแรงยามถูกสัมผัส ให้ความรู้สึกเหมือนกับว่าโอบกอดได้โดยไม่เกิดอันตราย) 
 
การที่ตัวประมวลผลสามารถประมวลผลอัลกอริทึมที่ซับซ้อนและข้อมูลจำนวนมากได้อย่างรวดเร็วมีผลทำให้แนวทางการศึกษาระบบควบคุมแตกต่างไปจากเดิมค่อนข้างมาก แม้ว่าหลักการพื้นฐานการวิเคราะห์ระบบควบคุมเช่นแผนภาพโบเดและไนควิสต์จะยังมีประโยชน์ แต่แนวโน้มคือใช้คอมพิวเตอร์ช่วยในการคำนวณในรูปแบบที่ไม่สามารถทำได้ในสมัยก่อน ตัวอย่างหนึ่งที่ชัดเจนคือการควบคุมแบบทำนายโมเดล (MPC : Model Predictive Control) ซึ่งมีการนำเสนอและใช้งานตั้งแต่ยุคเริ่มต้นของคอมพิวเตอร์ แต่เนื่องจากการคำนวณที่ซับซ้อนในแต่ละรอบการทำงาน ทำให้มีการใช้งานเฉพาะการควบคุมกระบวนการที่มีแบนด์วิดท์ต่ำ คือคาบเวลาการประมวลผลหน่วยเป็นนาที แต่ในปัจจุบันสามารถใช้ MPC ควบคุมหุ่นยนต์ที่ต้องการการตอบสนองอย่างรวดเร็วได้อย่างมีประสิทธิภาพ เป็นตัวอย่างหนึ่งของการควบคุมที่แตกต่างจากวิธีการออกแบบเพียงครั้งเดียวและใช้ในลูปป้อนกลับตลอดไป แต่จะมีการหาคำตอบเหมาะที่สุดในแต่ละคาบเวลาการทำงาน และมีการประมาณค่าของโมเดลอย่างต่อเนื่องตลอดเวลา เป็นแนวทางของการควบคุมสมัยใหม่ที่ใช้คอมพิวเตอร์ให้เกิดประโยชน์สูงสุด

จากชื่อหนังสือ “การควบคุมเหมาะที่สุดและการเรียนรู้เสริมกำลัง” ฟังดูเหมือนเป็นการรวม 2 หัวข้อที่ไม่น่าจะเกี่ยวข้องกัน แต่เมื่อเริ่มเข้าใจแนวคิดและหลักการของแต่ละหัวข้อแล้ว จะพบว่าอยู่บนพื้นฐานที่เรียกได้ว่าเป็นคู่กัน กล่าวแบบติดตลกได้ว่า ผู้สนใจการควบคุมเหมาะที่สุดอาจเปรียบได้กับคนมองโลกในแง่ร้ายคิดถึงแต่การสูญเสีย คือดำเนินการเพื่อลดต้นทุนหรือการสูญเสียให้น้อยที่สุด ในขณะที่การเรียนรู้เสริมกำลังเป็นคนที่มองโลกในแง่ดี คิดถึงแต่รางวัล จะดำเนินการตามนโยบายเพื่อจะให้ได้รางวัลมากที่สุด ทางด้านคณิตศาสตร์คือการหาค่าน้อยที่สุดหรือมากที่สุดของฟังก์ชันจุดประสงค์ (objective function) โดยสอดคล้องกับเงื่อนไขบังคับ (constraints) ที่กำหนดโดยโจทย์ปัญหานั้น 

เนื้อหาส่วนใหญ่ของหนังสือนี้รวบรวมจากวีดีโอและสื่อการสอนจากมหาวิทยาลัยทั่วโลกที่เผยแพร่ออนไลน์ ซึ่งหลายส่วนยังมีลักษณะเป็นงานวิจัยที่ยังไม่ตกผลึก มีการเปลี่ยนแปลงอย่างต่อเนื่อง ผู้เขียนขอขอบคุณผู้เผยแพร่ความรู้ทั้งหมดที่ช่วยทำให้ผู้เริ่มต้นสามารถตามรอยศึกษาแนวทางนี้โดยไม่ต้องเริ่มจากศูนย์ และหวังว่าหนังสือนี้จะมีส่วนช่วยในลักษณะเดียวกันสำหรับผู้อ่าน 

* [บทที่ 1](/doc/chapter1_wip.pdf)
* [บทที่ 2](/doc/notebooks/chapter2.ipynb)

### วีดีโอ

* [บทที่ 2 (part I)](https://youtu.be/G9vPLkXH4xU) วิธีนิวตันสำหรับการหาค่าต่ำสุดแบบไม่มีเงื่อนไข
* [บทที่ 2 (part II)](https://youtu.be/CQnrUwwSABE) การหาค่าต่ำสุดแบบมีเงื่อนไขสมการโดยวิธีนิวตันและเกาส์-นิวตัน
* [บทที่ 2 (part III)](https://youtu.be/lcwDYIMo8Tw) การหาค่าเหมาะที่สุดแบบมีเงื่อนไขอสมการโดยวิธีลากรานเจียนแต่งเติม
* [บทที่ 2 (part IV)](https://youtu.be/dpSwE0_oo48) วิธีจุดภายใน การทำเรกูลาร์ไรเซชันและการค้นหาตามเส้นสำหรับปัญหามีเงื่อนไข
