# ocrl
## หนังสือ "การควบคุมเหมาะที่สุดและการเรียนรู้เสริมกำลัง"
## Optimal Control and Reinforcement Learning

### ดร.วโรดม ตู้จินดา

repo นี้สำหรับหนังสือตามชื่อด้านบน เขียนไปเรื่อยตามโอกาสอำนวย เนื่องจากเนื้อหาส่วนใหญ๋เปลี่ยนแปลงตลอดเวลา จึงไม่มีหมายกำหนดการแล้วเสร็จ 

คลิกที่ลิงก์ของแต่ละบทเพื่ออ่านออนไลน์หรือดาวน์โหลด notebook เพื่อรันโค้ด โดยต้องติดตั้งแพ็กเกจที่ใช้ในบทนั้นก่อน 

<hr>
<img src="https://raw.githubusercontent.com/dewdotninja/ocrl/refs/heads/main/doc/figs/ch2_eq_constraints.png" width=600 />
<hr>
 
### คำนำ

ในปัจจุบันที่คอมพิวเตอร์สมรรถนะสูงได้เข้ามามีส่วนในชีวิตของมนุษย์ในหลากหลายรูปแบบ ตั้งแต่อุปกรณ์เครื่องใช้ไฟฟ้า โทรศัพท์ รถยนต์ อุปกรณ์อำนวยความสะดวกต่างๆ จนถึงหุ่นยนต์ที่มีการพัฒนาอย่างต่อเนื่องเพื่อให้มีความฉลาด ตอบสนองความต้องการผู้ใช้งาน และปลอดภัยเมื่อทำงานอยู่ใกล้เรา (ผู้สอนวิชาหุ่นยนต์รายหนึ่งใช้คำว่า “huggable” ใช้การควบคุมแรงเพื่อทำให้เครื่องจักรกลโอนอ่อนตามแรงยามถูกสัมผัส ให้ความรู้สึกเหมือนกับว่าโอบกอดได้โดยไม่เกิดอันตราย) 
 
การที่ตัวประมวลผลสามารถประมวลผลอัลกอริทึมที่ซับซ้อนและข้อมูลจำนวนมากได้อย่างรวดเร็วมีผลทำให้แนวทางการศึกษาระบบควบคุมแตกต่างไปจากเดิมค่อนข้างมาก แม้ว่าหลักการพื้นฐานการวิเคราะห์ระบบควบคุมเช่นแผนภาพโบเดและไนควิสต์จะยังมีประโยชน์ แต่แนวโน้มคือใช้คอมพิวเตอร์ช่วยในการคำนวณในรูปแบบที่ไม่สามารถทำได้ในสมัยก่อน ตัวอย่างหนึ่งที่ชัดเจนคือการควบคุมแบบทำนายโมเดล (MPC : Model Predictive Control) ซึ่งมีการนำเสนอและใช้งานตั้งแต่ยุคเริ่มต้นของคอมพิวเตอร์ แต่เนื่องจากการคำนวณที่ซับซ้อนในแต่ละรอบการทำงาน ทำให้มีการใช้งานเฉพาะการควบคุมกระบวนการที่มีแบนด์วิดท์ต่ำ คือคาบเวลาการประมวลผลหน่วยเป็นนาที แต่ในปัจจุบันสามารถใช้ MPC ควบคุมหุ่นยนต์ที่ต้องการการตอบสนองอย่างรวดเร็วได้อย่างมีประสิทธิภาพ เป็นตัวอย่างหนึ่งของการควบคุมที่แตกต่างจากวิธีการออกแบบเพียงครั้งเดียวและใช้ในลูปป้อนกลับตลอดไป แต่จะมีการหาคำตอบเหมาะที่สุดในแต่ละคาบเวลาการทำงาน และมีการประมาณค่าของโมเดลอย่างต่อเนื่องตลอดเวลา เป็นแนวทางของการควบคุมสมัยใหม่ที่ใช้คอมพิวเตอร์ให้เกิดประโยชน์สูงสุด

จากชื่อหนังสือ “การควบคุมเหมาะที่สุดและการเรียนรู้เสริมกำลัง” ฟังดูเหมือนเป็นการรวม 2 หัวข้อที่ไม่น่าจะเกี่ยวข้องกัน แต่เมื่อเริ่มเข้าใจแนวคิดและหลักการของแต่ละหัวข้อแล้ว จะพบว่าอยู่บนพื้นฐานที่เรียกได้ว่าเป็นคู่กัน กล่าวแบบติดตลกได้ว่า ผู้สนใจการควบคุมเหมาะที่สุดอาจเปรียบได้กับคนมองโลกในแง่ร้ายคิดถึงแต่การสูญเสีย คือดำเนินการเพื่อลดต้นทุนหรือการสูญเสียให้น้อยที่สุด ในขณะที่การเรียนรู้เสริมกำลังเป็นคนที่มองโลกในแง่ดี คิดถึงแต่รางวัล จะดำเนินการตามนโยบายเพื่อจะให้ได้รางวัลมากที่สุด ทางด้านคณิตศาสตร์คือการหาค่าน้อยที่สุดหรือมากที่สุดของฟังก์ชันจุดประสงค์ (objective function) โดยสอดคล้องกับเงื่อนไขบังคับ (constraints) ที่กำหนดโดยโจทย์ปัญหานั้น 

เนื้อหาส่วนใหญ่ของหนังสือนี้รวบรวมจากวีดีโอและสื่อการสอนจากมหาวิทยาลัยทั่วโลกที่เผยแพร่ออนไลน์ ซึ่งหลายส่วนยังมีลักษณะเป็นงานวิจัยที่ยังไม่ตกผลึก มีการเปลี่ยนแปลงอย่างต่อเนื่อง ผู้เขียนขอขอบคุณผู้เผยแพร่ความรู้ทั้งหมดที่ช่วยทำให้ผู้เริ่มต้นสามารถตามรอยศึกษาแนวทางนี้โดยไม่ต้องเริ่มจากศูนย์ และหวังว่าหนังสือนี้จะมีส่วนช่วยในลักษณะเดียวกันสำหรับผู้อ่าน 

<hr>

### สารบัญ

* [บทที่ 1](/doc/chapter1_wip.pdf) : บทนำ
<ul>
<ul>
<li />1.1 ต้นกำเนิดของการควบคุมเหมาะที่สุด
<li />1.2 ปัญหาการหาค่าเหมาะที่สุด
<ul>
<li />1.2.1 หลักการของความเหมาะที่สุด
<li />1.2.2 การจัดรูปปัญหาทางคณิตศาสตร์
</ul>
<li />1.3 เครื่องมือซอฟต์แวร์
<li />1.4 สรุปท้ายบท
<li />บรรณานุกรม
<li />โจทย์ปัญหา
</ul>
</ul>

* [บทที่ 2](/doc/notebooks/chapter2.ipynb) พื้นฐานการหาค่าเหมาะที่สุด

<ul>
<ul>
<li />2.1 อัลกอริทึมสำหรับหาคำตอบเหมาะที่สุด
<ul>
<li />2.1.1 เงื่อนไขจำเป็นสำหรับค่าต่ำสุด
<li />2.1.2 การหาค่ารากโดยวิธีนิวตัน
<li />2.1.3 การหาค่าต่ำสุดของฟังก์ชันโดยวิธีหาค่าราก
<li />2.1.4 วิธีการเรกูลาร์ไรเชชัน
<li />2.1.5 การค้นหาตามเส้น
</ul>
<li />2.2 ปัญหาการหาค่าเหมาะที่สุดแบบมีเงื่อนไข
<ul>
<li />2.2.1 เงื่อนไขบังคับแบบสมการ
<li />2.2.2 วิธีการเกาส์-นิวตัน
<li />2.2.3 เงื่อนไขบังคับแบบอสมการ
<li />2.2.4 วิธีเลือกเซตที่แอ็กทิฟ
<li />2.2.5 วิธีการลงโทษ
<li />2.2.6 วิธีลากรานเจียนแต่งเติม
<li />2.2.7 วิธีจุดภายใน
</ul>
<li />2.3 ปรับปรุงการหาค่าเหมาะที่สุดแบบมีเงื่อนไข
<ul>
<li />2.3.1 วิธีการเรกูลาร์ไรเซชัน
<li />2.3.2 วิธีการค้นหาตามเส้น
</ul>
<li />2.4 สรุปท้ายบท
<li />บรรณานุกรม
<li />โจทย์ปัญหา
</ul>
</ul>

* [บทที่ 3](/doc/notebooks/chapter3.ipynb) การควบคุมเหมาะที่สุด
<ul>
<ul>
<li />3.1 การควบคุมเหมาะที่สุดแบบเชิงกำหนด
<ul>
<li />3.1.1 รูปแบบปัญหาในโดเมนเวลาต่อเนื่อง
<li />3.1.2 รูปแบบปัญหาในโดเมนเวลาดีสครีต
<li />3.1.3 หลักการค่าต่ำสุดของพอนเทรียกิน
</ul>
<li />3.2 ตัวควบคุมกำลังสองเชิงเส้น
<ul>
<li />3.2.1 การหาคำตอบโดยวิธีการยิงโดยอ้อม
<li />3.2.2 การหาคำตอบโดยการโปรแกรมกำลังสอง
<li />3.2.3 การหาคำตอบโดยสมการริกคาติ
<li />3.2.4 ตัวควบคุม LQR แบบแนวนอนอนันต์
</ul>
<li />3.3 คุณสมบัติควบคุมได้ของระบบพลวัต
<li />3.4 สรุปท้ายบท
<li />บรรณานุกรม
<li />โจทย์ปัญหา
</ul>
</ul>
<hr>

### วีดีโอ

* [บทที่ 2 (part I)](https://youtu.be/G9vPLkXH4xU) วิธีนิวตันสำหรับการหาค่าต่ำสุดแบบไม่มีเงื่อนไข
* [บทที่ 2 (part II)](https://youtu.be/CQnrUwwSABE) การหาค่าต่ำสุดแบบมีเงื่อนไขสมการโดยวิธีนิวตันและเกาส์-นิวตัน
* [บทที่ 2 (part III)](https://youtu.be/lcwDYIMo8Tw) การหาค่าเหมาะที่สุดแบบมีเงื่อนไขอสมการโดยวิธีลากรานเจียนแต่งเติม
* [บทที่ 2 (part IV)](https://youtu.be/dpSwE0_oo48) วิธีจุดภายใน การทำเรกูลาร์ไรเซชันและการค้นหาตามเส้นสำหรับปัญหามีเงื่อนไข
